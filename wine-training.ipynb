{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c52397-e2b3-4d3f-8a6e-7e9ddd0f5cfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T05:13:13.238892Z",
     "iopub.status.busy": "2024-12-11T05:13:13.238675Z",
     "iopub.status.idle": "2024-12-11T05:13:36.596165Z",
     "shell.execute_reply": "2024-12-11T05:13:36.595183Z",
     "shell.execute_reply.started": "2024-12-11T05:13:13.238868Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851614902b3f49bd81b6d164ab7ddbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.21.6\n",
      "  Downloading numpy-1.21.6-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.21.6\n",
      "\n",
      "Collecting pandas==1.3.3\n",
      "  Downloading pandas-1.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3.9/site-packages (from pandas==1.3.3) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./tmp/spark-4651621c-a56d-46fe-859c-c0723b785304/lib64/python3.9/site-packages (from pandas==1.3.3) (1.21.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/site-packages (from pandas==1.3.3) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas==1.3.3) (1.13.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.3.3\n",
      "\n",
      "Collecting quinn\n",
      "  Downloading quinn-0.10.3-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: quinn\n",
      "Successfully installed quinn-0.10.3\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag."
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"numpy==1.21.6\")\n",
    "sc.install_pypi_package(\"pandas==1.3.3\")\n",
    "sc.install_pypi_package(\"quinn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "605fb13b-0313-4851-907c-193faf03bd24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T05:13:36.597941Z",
     "iopub.status.busy": "2024-12-11T05:13:36.597676Z",
     "iopub.status.idle": "2024-12-11T05:13:37.355569Z",
     "shell.execute_reply": "2024-12-11T05:13:37.354758Z",
     "shell.execute_reply.started": "2024-12-11T05:13:36.597901Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091e73ff8ff34c85bfecd427b113d4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 1.3.3\n",
      "Numpy version: 1.21.6"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import quinn\n",
    "\n",
    "\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Numpy version:\", np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18487f50-3026-4c98-81d2-0ef85de6c784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T05:13:43.987004Z",
     "iopub.status.busy": "2024-12-11T05:13:43.986777Z",
     "iopub.status.idle": "2024-12-11T05:14:28.144868Z",
     "shell.execute_reply": "2024-12-11T05:14:28.144262Z",
     "shell.execute_reply.started": "2024-12-11T05:13:43.986978Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db6d676d1704046b258d55498b83ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/notebook-env/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in cell_monitor\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "  File \"/mnt/notebook-env/lib/python3.9/site-packages/awseditorssparkmonitoringwidget/cellmonitor.py\", line 154, in <listcomp>\n",
      "    job_group_filtered_jobs = [job for job in jobs_data if job['jobGroup'] == str(statement_id)]\n",
      "KeyError: 'jobGroup'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from S3 bucket.\n",
      "   \"\"\"\"\"fixed acidity\"\"\"\"  ...  \"\"\"\"quality\"\"\"\"\"\n",
      "0                     8.9  ...                 6\n",
      "1                     7.6  ...                 5\n",
      "2                     7.9  ...                 5\n",
      "3                     8.5  ...                 5\n",
      "4                     6.9  ...                 6\n",
      "\n",
      "[5 rows x 12 columns]\n",
      "Data has been formatted.\n",
      "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  label\n",
      "0            8.9              0.22         0.48  ...       0.53      9.4      6\n",
      "1            7.6              0.39         0.31  ...       0.65      9.7      5\n",
      "2            7.9              0.43         0.21  ...       0.91      9.5      5\n",
      "3            8.5              0.49         0.11  ...       0.53      9.4      5\n",
      "4            6.9              0.40         0.14  ...       0.63      9.7      6\n",
      "\n",
      "[5 rows x 12 columns]\n",
      "F1 Score for LogisticRegression Model:  0.5729445029855991\n",
      "F1 Score for RandomForestClassifier Model:  0.5149515912576688\n",
      "Since the Logistic Regression model has the superior F1 score, it will be selected for the prediction application."
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, Normalizer, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"CS643_Project\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "## Load Training Dataset\n",
    "train_df = spark.read.format('csv').options(header='true', inferSchema='true', sep=';').load('s3://cs643rudolphpaulin/TrainingDataset.csv')\n",
    "validation_df = spark.read.format('csv').options(header='true', inferSchema='true', sep=';').load('s3://cs643rudolphpaulin/ValidationDataset.csv')\n",
    "\n",
    "print(\"Data loaded from S3 bucket.\")\n",
    "print(train_df.toPandas().head())\n",
    "\n",
    "def remove_quotations(s):\n",
    "    return s.replace('\"', '')\n",
    "\n",
    "train_df = quinn.with_columns_renamed(remove_quotations)(train_df)\n",
    "train_df = train_df.withColumnRenamed('quality', 'label')\n",
    "\n",
    "validation_df = quinn.with_columns_renamed(remove_quotations)(validation_df)\n",
    "validation_df = validation_df.withColumnRenamed('quality', 'label')\n",
    "\n",
    "print(\"Data has been formatted.\")\n",
    "print(train_df.toPandas().head())\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"fixed acidity\",\n",
    "               \"volatile acidity\",\n",
    "               \"citric acid\",\n",
    "               \"residual sugar\",\n",
    "               \"chlorides\",\n",
    "               \"free sulfur dioxide\",\n",
    "               \"total sulfur dioxide\",\n",
    "               \"density\",\n",
    "               \"pH\",\n",
    "               \"sulphates\",\n",
    "               \"alcohol\"],\n",
    "                outputCol=\"inputFeatures\")\n",
    "\n",
    "scaler = Normalizer(inputCol=\"inputFeatures\", outputCol=\"features\")\n",
    "\n",
    "lr = LogisticRegression()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "pipeline1 = Pipeline(stages=[assembler, scaler, lr])\n",
    "pipeline2 = Pipeline(stages=[assembler, scaler, rf])\n",
    "\n",
    "paramgrid = ParamGridBuilder().build()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline1,  \n",
    "                         estimatorParamMaps=paramgrid,\n",
    "                         evaluator=evaluator, \n",
    "                         numFolds=3\n",
    "                        )\n",
    "\n",
    "cvModel1 = crossval.fit(train_df) \n",
    "print(\"F1 Score for LogisticRegression Model: \", evaluator.evaluate(cvModel1.transform(validation_df)))\n",
    "\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline2,  \n",
    "                         estimatorParamMaps=paramgrid,\n",
    "                         evaluator=evaluator, \n",
    "                         numFolds=3\n",
    "                        )\n",
    "\n",
    "cvModel2 = crossval.fit(train_df) \n",
    "print(\"F1 Score for RandomForestClassifier Model: \", evaluator.evaluate(cvModel2.transform(validation_df)))\n",
    "\n",
    "print(\"Since the Logistic Regression model has the superior F1 score, it will be selected for the prediction application.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef84517-2cad-4fbd-b98e-64877acdb63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ece9cb-465c-4a43-bd1d-a7ee05863f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
